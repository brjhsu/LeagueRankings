{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:20:30.961725700Z",
     "start_time": "2023-10-03T02:20:29.495233500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from data_processing.utils.download_functions import *\n",
    "from copy import deepcopy\n",
    "import pickle \n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "\n",
    "os.chdir('esports-data')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec6f13987bbfde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T03:05:07.492857600Z",
     "start_time": "2023-10-03T03:05:07.437434700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataAggregator:\n",
    "    \"\"\"\n",
    "    Class to aggregate the data from the different years into one dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # SET CONSTANTS FOR DATA PROCESSING\n",
    "        self._window_size = 20\n",
    "        self._ewm_alpha = 0.05\n",
    "        self._ma_min_periods = 1\n",
    "\n",
    "        self.league_indicators_to_drop = ['League_TFT Rising Legends', 'League_All-Star Event', 'League_MSI', 'League_Worlds', 'League_EMEA Masters']\n",
    "        self.non_game_features = ['platformGameId', 'esportsGameId', 'team_id', 'start_time', 'tournament_name']\n",
    "        self.league_indicators = ['League_Arabian League','League_CBLOL','League_CBLOL Academy','League_College Championship','League_Elite Series','League_Esports Balkan League',\n",
    "                         'League_Greek Legends League','League_Hitpoint Masters','League_LCK','League_LCK Academy','League_LCK Challengers','League_LCL','League_LCO','League_LCS',\n",
    "                         'League_LCS Challengers','League_LCS Challengers Qualifiers','League_LEC','League_LJL','League_LJL Academy','League_LLA','League_LPL','League_La Ligue FranÃ§aise',\n",
    "                         'League_Liga Portuguesa','League_NLC','League_North Regional League','League_PCS','League_PG Nationals','League_Prime League',\n",
    "                         'League_South Regional League','League_SuperLiga','League_TCL','League_Ultraliga','League_VCS']\n",
    "        # Include a set of features that are known to be important for the model \n",
    "        self.mandatory_features = ['outcome', 'outcome_domestic', 'outcome_international', 'domestic_game_ind', \n",
    "                                   'eSportsLeague_1', 'eSportsLeague_2', 'eliteLeague_1', 'eliteLeague_2', 'majorLeague_1', 'majorLeague_2', 'year']\n",
    "        # Mark special features that require a different style of processing \n",
    "        self.special_features = ['outcome_domestic', 'outcome_international']\n",
    "\n",
    "        self. important_features = ['team_1', 'team_2', 'outcome', 'outcome_domestic', 'outcome_international', 'eSportsLeague_1', 'eSportsLeague_2', \n",
    "                      'team_share_of_totalGold_at_20', 'team_share_of_totalGold_at_game_end', \n",
    "                      'team_share_of_towerKills_at_20', 'team_share_of_towerKills_at_game_end', 'team_share_of_VISION_SCORE_at_game_end']\n",
    "\n",
    "        \n",
    "        # Maintain a manual dictionary of team_id to league_indicator. This is necessary to mark the regions for teams in international tournaments (MSI/worlds since LPL teams don't have data)\n",
    "        # Loop through this and mark the league_indicator for each team_id as =1 for the rows where the team_id is present\n",
    "        self.league_indicator_dict = {\n",
    "            98767991954244555: 'League_VCS', # GAM\n",
    "            107251245690956393: 'League_VCS', # SAIGON BUFFALOS\n",
    "            98767991892579754: 'League_LPL',  # RNG\n",
    "            104367068120825486: 'League_PCS',  # PSG Talon\n",
    "            98767991882270868: 'League_LPL',  # EDG\n",
    "            99566404850008779: 'League_LPL',  # LNG\n",
    "            99566404855553726: 'League_LPL',  # FPX\n",
    "            99566404852189289: 'League_LPL',  # JDG\n",
    "            99566404854685458: 'League_LPL',  # TES\n",
    "            105520788833075738: 'League_Elite Series', # KV Mechelen\n",
    "            105520824521753126: 'League_NLC', # PSV Esports\n",
    "            105543843212923183: 'League_Ultraliga', # Goskilla\n",
    "            105548000936710641: 'League_Ultraliga', # Method2Madness\n",
    "            103935642731826448: 'League_Elite Series', # Sector One\n",
    "            104710682193583854: 'League_Ultraliga', # Topo Centras Iron Wolves\n",
    "            105520822049210915: 'League_Elite Series', # Team mCon\n",
    "            106334794714373670: 'League_Ultraliga', # Goexanimo\n",
    "        }\n",
    "        \n",
    "        # Read in teams data\n",
    "        with open(\"teams.json\", \"r\") as json_file:\n",
    "           teams_data = json.load(json_file)\n",
    "        teams_dict = {}\n",
    "        for team in teams_data:\n",
    "            teams_dict[team['team_id']] = team['name']\n",
    "        self.teams_dict = teams_dict\n",
    "        \n",
    "    def get_featurized_data(self, folder_paths, years):\n",
    "        \"\"\"\n",
    "        We do the following steps to process the game data\n",
    "        1) Read in the tournament rows data, which specifies the match ID, the participating teams, and the winner of the match \n",
    "        2) Read in the game rows data, which contains all the granular information about each game \n",
    "        3) Additionally process the game rows data\n",
    "            i) Sort the game rows by team_id and start_time\n",
    "            ii) Create features based on the stats of the team over historical games \n",
    "            iii) Handle the league region indicators for each time (as 'eSportLeague')\n",
    "            iv) \n",
    "        :param folder_paths: list of strings specifying the folder paths\n",
    "        :param years: list of strings specifying the years \n",
    "        :return: \n",
    "            model_data - dataframe containing the diff between the two teams for each game used for training\n",
    "            processed_game_data_inf_inf_inf - dataframe containing the processed game data for each individual team used for inference\n",
    "        \"\"\"\n",
    "        tournament_rows = pd.DataFrame()\n",
    "        game_rows = pd.DataFrame()\n",
    "        for (folder_path, year) in zip(folder_paths, years):\n",
    "            file_names = os.listdir(folder_path)\n",
    "\n",
    "            # Get the unique tournament names by stripping out '_game_rows.csv' and '_tournament_rows.csv'\n",
    "            unique_tournament_names = [file_name.split('_game_rows.csv')[0] for file_name in file_names]\n",
    "            unique_tournament_names = [x.replace('_tournament_rows.csv', '') for x in unique_tournament_names]\n",
    "            unique_tournament_names = list(set(unique_tournament_names))\n",
    "\n",
    "            # Aggregate all the game rows into one dataframe, start with an empty dataframe and append onto it to save memory\n",
    "            \n",
    "            for tournament_name in tqdm(unique_tournament_names):\n",
    "                df_tmp = pd.read_csv(f'{folder_path}/' + tournament_name + '_tournament_rows.csv')\n",
    "                # Add a column to indicate the tournament name\n",
    "                df_tmp['tournament_name'] = tournament_name\n",
    "                tournament_rows = pd.concat([tournament_rows, df_tmp])\n",
    "            print(\"Tournament rows shape: \", tournament_rows.shape)\n",
    "\n",
    "            \n",
    "            for tournament_name in tqdm(unique_tournament_names):\n",
    "                df_tmp = pd.read_csv(f'{folder_path}/' + tournament_name + '_game_rows.csv', index_col=0)\n",
    "                # Add a column to indicate the tournament name\n",
    "                df_tmp['tournament_name'] = tournament_name\n",
    "                df_tmp['year'] = year\n",
    "                game_rows = pd.concat([game_rows, df_tmp])\n",
    "            print(\"Game rows shape: \", game_rows.shape)\n",
    "\n",
    "        print(\"Completed data loading\")\n",
    "        print(\"Tourament rows shape: \", tournament_rows.shape)\n",
    "        print(\"Game rows shape: \", game_rows.shape)\n",
    "\n",
    "        game_rows = game_rows.drop(columns=self.league_indicators_to_drop, axis=1)\n",
    "        game_features = [x for x in game_rows.columns if x not in self.non_game_features + self.league_indicators + self.special_features + ['year']]\n",
    "        self.game_features = game_features\n",
    "        \n",
    "        # Get a set of all team IDs as we will iterate through them to generate the row data for each team \n",
    "        all_team_ids = np.unique(game_rows['team_id'])\n",
    "        processed_game_data = self.featurize_game_rows(game_rows, all_team_ids)\n",
    "        processed_game_data = self.refine_league_indicator_data(processed_game_data)\n",
    "        self.game_features = game_features + self.special_features\n",
    "\n",
    "        valid_games = self.get_valid_game_rows(tournament_rows, processed_game_data)\n",
    "        model_data = self.get_model_data(valid_games, processed_game_data)\n",
    "        return model_data, processed_game_data\n",
    "    \n",
    "    def featurize_game_rows(self, game_rows, all_team_ids, averaging_method='ewm'):\n",
    "        \"\"\"\n",
    "        averaging_method must be either 'ewm' or 'mean'\n",
    "        \"\"\"\n",
    "        processed_game_data = []\n",
    "        for team in tqdm(all_team_ids):\n",
    "            team_data = game_rows[game_rows['team_id']==team].reset_index()\n",
    "            team_data = team_data.sort_values(by=['start_time'])\n",
    "            team_data['num_prev_games'] = np.arange(len(team_data))\n",
    "            team_data['outcome_domestic'] = np.nan\n",
    "            team_data['outcome_international'] = np.nan\n",
    "            # Set outcome_international for worlds and msi tournaments\n",
    "            team_data.loc[team_data['tournament_name'].str.contains('worlds|msi'), 'outcome_international'] = team_data['outcome']\n",
    "            # Set outcome_domestic for non-worlds and non-msi tournaments\n",
    "            team_data.loc[~team_data['tournament_name'].str.contains('worlds|msi'), 'outcome_domestic'] = team_data['outcome']\n",
    "            \n",
    "            # First lag by 1 game so that the current game is not included in the average. Then take the mean as the trailing average \n",
    "            if averaging_method == 'ewm':\n",
    "                team_data_features = team_data[self.game_features + self.special_features].shift(1).ewm(alpha=self._ewm_alpha, min_periods=self._ma_min_periods, ignore_na=False).mean()\n",
    "            elif averaging_method == 'mean':\n",
    "                team_data_features = team_data[self.game_features + self.special_features].shift(1).rolling(window=self._window_size, min_periods=1).mean()\n",
    "            else:\n",
    "                raise ValueError('averaging_method must be either \"ewm\" or \"mean\"')\n",
    "            \n",
    "            team_data[self.game_features + self.special_features] = team_data_features \n",
    "            # Drop rows where num_prev_games == 0 as this indicates that it's the team's first game \n",
    "            team_data = team_data[team_data['num_prev_games']!=0]\n",
    "        \n",
    "            # Add the team name to the dataframe\n",
    "            try:\n",
    "                team_name = self.teams_dict[str(team)]\n",
    "            except KeyError:\n",
    "                team_name = \"NULL\"\n",
    "            # Add a column for the team name\n",
    "            team_data['team_name'] = team_name\n",
    "        \n",
    "            # Determine the team's primary league\n",
    "            team_league = team_data[self.league_indicators].mean(axis=0).idxmax()\n",
    "            # Determine if it's a valid league (otherwise it'll just mark the first one)\n",
    "            team_league_check = team_data[team_league].sum() > 0 # If false, then do not mark based on history, have to manually mark \n",
    "            \n",
    "            # check if there are any rows where the team does not have a league_indicator (i.e., np.sum(team_data[league_indicators]) == 0) and if so, mark the team_league as 1 for those rows\n",
    "            # This happens when a team plays in international tournaments \n",
    "            if team_league_check:\n",
    "                team_data.loc[np.sum(team_data[self.league_indicators], axis=1)==0, team_league] = 1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "            # update the processed_game_data with the new league_indicator values\n",
    "            processed_game_data.append(team_data)\n",
    "        \n",
    "        del game_rows  # Don't need this anymore once we're done processing them\n",
    "        \n",
    "        processed_game_data = pd.concat(processed_game_data)\n",
    "        processed_game_data.drop('index', axis=1, inplace=True)\n",
    "        return processed_game_data\n",
    "    \n",
    "    def refine_league_indicator_data(self, processed_game_data):\n",
    "        # Next deal with marking specific team's leagues \n",
    "        for team_id, league_indicator in self.league_indicator_dict.items():\n",
    "            processed_game_data.loc[processed_game_data['team_id']==team_id, league_indicator] = 1\n",
    "            \n",
    "        # Create two additional features related to the esport league\n",
    "        # If the team is an LPL or LCK team, mark indicator 'eliteLeague' as 1\n",
    "        # If the team is an LEC, LCS, LPL, or LCK team, mark indicator 'majorLeague' as 1\n",
    "        processed_game_data['eliteLeague'] = (processed_game_data['League_LPL'] == 1) | (processed_game_data['League_LCK'] == 1)\n",
    "        processed_game_data['majorLeague'] = (processed_game_data['League_LPL'] == 1) | (processed_game_data['League_LCK'] == 1) | \\\n",
    "                                             (processed_game_data['League_LCS'] == 1) | (processed_game_data['League_LEC'] == 1)\n",
    "        \n",
    "        # Check that the one-hot encoding worked correctly\n",
    "        if (np.sum(processed_game_data[self.league_indicators], axis=1) == 1).all():\n",
    "            # Convert the league_indicator one-hot encoded columns to categorical variables\n",
    "            for league in [x.replace('League_', '') for x in self.league_indicators]:\n",
    "                processed_game_data['League_' + league] = processed_game_data['League_' + league].apply(lambda x: league if x==1 else '')\n",
    "            # Combine it into a single column\n",
    "            processed_game_data['eSportLeague'] = processed_game_data[self.league_indicators].apply(lambda x: ''.join(x), axis=1)\n",
    "            processed_game_data = processed_game_data.drop(columns=self.league_indicators, axis=1)\n",
    "            # Convert it to a categorical variable\n",
    "            processed_game_data['eSportLeague'] = processed_game_data['eSportLeague'].astype('category')\n",
    "        else:\n",
    "            raise ValueError('One-hot encoding of league_indicators did not work correctly')\n",
    "        return processed_game_data\n",
    "        \n",
    "    def get_valid_game_rows(self, tournament_rows, processed_game_data):\n",
    "        valid_games = tournament_rows.merge(processed_game_data[['esportsGameId', 'team_id']], how='inner', \n",
    "                                    left_on=['esportsGameId', 'team_id_1'], \n",
    "                                    right_on=['esportsGameId', 'team_id'], \n",
    "                                    suffixes=['_to_drop','_to_drop'])\n",
    "        valid_games = valid_games.merge(processed_game_data[['esportsGameId', 'team_id']], how='inner', \n",
    "                                            left_on=['esportsGameId', 'team_id_2'], \n",
    "                                            right_on=['esportsGameId', 'team_id'],\n",
    "                                            suffixes=['_to_drop','_to_drop'])\n",
    "        valid_games.drop([x for x in valid_games.columns if '_to_drop' in x], axis=1, inplace=True)\n",
    "        return valid_games \n",
    "        \n",
    "    def get_model_data(self, valid_games, processed_game_data):\n",
    "        # Merge processed_game_data with tournament_rows for team 1\n",
    "        team_1_data = valid_games.merge(processed_game_data, how='inner', \n",
    "                                            left_on=['esportsGameId', 'team_id_1'], \n",
    "                                            right_on=['esportsGameId', 'team_id'],\n",
    "                                            suffixes=['_to_drop','_to_drop'])\n",
    "        \n",
    "        # Merge processed_game_data with tournament_rows for team 2\n",
    "        team_2_data = valid_games.merge(processed_game_data, how='inner', \n",
    "                                            left_on=['esportsGameId', 'team_id_2'], \n",
    "                                            right_on=['esportsGameId', 'team_id'],\n",
    "                                            suffixes=['_to_drop','_to_drop'])\n",
    "        \n",
    "        # Calculate the difference between the two teams for esportsGameId and for each feature\n",
    "        check_esportsGameId = np.all(team_1_data['esportsGameId'] == team_2_data['esportsGameId'])\n",
    "        check_team1_id = np.all(team_1_data['team_id_1'] == team_2_data['team_id_1'])\n",
    "        check_team2_id = np.all(team_1_data['team_id_2'] == team_2_data['team_id_2'])\n",
    "        \n",
    "        if check_esportsGameId and check_team1_id and check_team2_id:\n",
    "            # Calculate the difference between the two teams for each feature\n",
    "            difference_data = team_1_data[self.game_features].subtract(team_2_data[self.game_features])\n",
    "            # Apply special logic for computing the difference for the \"outcome_domestic\" and \"outcome_international\" features \n",
    "            for feature in self.special_features:\n",
    "                # Calculate the difference between columns A and B\n",
    "                diff = team_1_data[feature].fillna(0).sub(team_2_data[feature].fillna(0)) \n",
    "                # If both columns are nan then mark the difference as nan\n",
    "                diff[(team_1_data[feature].isna()) & (team_2_data[feature].isna())] = np.nan\n",
    "        else:\n",
    "            raise Exception('esportsGameId is not the same for the two teams')\n",
    "        \n",
    "        self.difference_data = difference_data.columns\n",
    "        # Add the difference data to the tournament_rows dataframe as well as the league data for each team\n",
    "        training_data = deepcopy(valid_games)\n",
    "        training_data = pd.concat([training_data.reset_index(), difference_data], axis=1)\n",
    "        training_data['eSportsLeague_1'] = team_1_data['eSportLeague']\n",
    "        training_data['eSportsLeague_2'] = team_2_data['eSportLeague']\n",
    "        training_data['domestic_game_ind'] = training_data['eSportsLeague_1'] == training_data['eSportsLeague_2'] \n",
    "        training_data['eliteLeague_1'] = team_1_data['eliteLeague']\n",
    "        training_data['eliteLeague_2'] = team_2_data['eliteLeague']\n",
    "        training_data['majorLeague_1'] = team_1_data['majorLeague']\n",
    "        training_data['majorLeague_2'] = team_2_data['majorLeague']\n",
    "        training_data['team_1'] = team_1_data['team_name']\n",
    "        training_data['team_2'] = team_2_data['team_name']\n",
    "        training_data['start_time'] = team_1_data['start_time']\n",
    "        training_data['year'] = team_1_data['year']\n",
    "        \n",
    "        # Drop the columns that were used for joining (have '_to_drop' suffix). \n",
    "        training_data.drop([x for x in training_data.columns if '_to_drop' in x] + ['index'], axis=1, inplace=True)\n",
    "        \n",
    "        # drop the games where the outcome is NaN, those games are when one team has not had any games yet\n",
    "        training_data.dropna(subset=['outcome'], inplace=True)\n",
    "        \n",
    "        del team_1_data, team_2_data, difference_data\n",
    "        return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23923ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aggregator = DataAggregator()\n",
    "model_data, game_data = data_aggregator.get_featurized_data(['2021_raw_game_data', '2022_raw_game_data', '2023_raw_game_data'] ,['2021', '2022', '2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this cell was run in a separate notebook for feature selection, at this point it is already completed so we just read in the 200 selected features \n",
    "\"\"\"\n",
    "# First do some feature selection on X_train using catboost algorithms, use default parameters \n",
    "from catboost import EShapCalcType, EFeaturesSelectionAlgorithm\n",
    "model = CatBoostClassifier(iterations=10, learning_rate=0.05, depth=10, l2_leaf_reg=5, random_strength= 1.5, task_type=\"GPU\", devices='0:1', silent=True)\n",
    "summary = model.select_features(\n",
    "        train_data,\n",
    "        eval_set=val_data,\n",
    "        features_for_select=list(range(X_train.shape[1])),     # we will select from all features\n",
    "        num_features_to_select=200, \n",
    "        steps=1,                                     # more steps - more accurate selection\n",
    "        algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues,\n",
    "        shap_calc_type=EShapCalcType.Approximate,            # can be Approximate, Regular and Exact\n",
    "        train_final_model=True,                          # to train model with selected features\n",
    "        logging_level='Verbose',\n",
    "        plot=False\n",
    ")\n",
    "\"\"\"\n",
    "    \n",
    "# Read in the selected features as a list\n",
    "with open(\"selected_features_RSV_Approx_200.txt\", \"rb\") as fp:   # Unpickling\n",
    "    selected_features = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbf2bcf8899b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:56:42.896912100Z",
     "start_time": "2023-10-01T05:56:42.455106400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure that important features are in selected_features and if not, add them\n",
    "# Do this by taking the union of the selected features and the mandatory features\n",
    "model_features = list(set(selected_features + data_aggregator.mandatory_features + data_aggregator.special_features)) + ['team_1', 'team_2']\n",
    "model_features.remove('outcome')\n",
    "\n",
    "with open(\"model_features.txt\", \"wb\") as fp:  #Pickling\n",
    "    pickle.dump(model_features, fp)\n",
    "\n",
    "target_col = 'outcome_1'\n",
    "X = model_data.drop(['match_id', 'esportsGameId', 'league', 'team_id_1', 'outcome_1', 'team_id_2', 'outcome_2', 'start_time'], axis=1)\n",
    "y = model_data[target_col]\n",
    "\n",
    "# Split into train/val/test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=102)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=22)\n",
    "\n",
    "# Get all indices where X_train['tournment_name'] contains ['worlds', 'msi'] \n",
    "international_ix_train = X_train['tournament_name'].str.contains('worlds|msi')\n",
    "international_ix_test = X_val['tournament_name'].str.contains('worlds|msi')\n",
    "\n",
    "# Set the tournament weights based on prior on which regions play the game \"well\"\n",
    "tournamnent_weights = {\n",
    "    'lcs': 5,\n",
    "    'lec': 10,\n",
    "    'lck': 20,\n",
    "    'lpl': 20,\n",
    "    'worlds|msi': 50}\n",
    "\n",
    "def set_tournament_weights(X_train, tournament_weights):\n",
    "    \"\"\"\n",
    "    Set the tournament weights for the training data based on the given dictionary of tournament names and weights.\n",
    "    :param X_train: pandas dataframe containing the training data\n",
    "    :param tournament_weights: dictionary containing the tournament names and weights\n",
    "    :return: numpy array containing the weights for the training data\n",
    "    \"\"\"\n",
    "    weights_train = np.ones(len(X_train))\n",
    "    for tournament_name, weight in tournament_weights.items():\n",
    "        tournament_ix_train = X_train['tournament_name'].str.contains(tournament_name)\n",
    "        weights_train[tournament_ix_train] = weight\n",
    "    return weights_train\n",
    "\n",
    "weights_train = set_tournament_weights(X_train, tournament_weights=tournamnent_weights)\n",
    "\n",
    "X_train = X_train.drop('tournament_name', axis=1)\n",
    "X_train = X_train[model_features]\n",
    "train_data = Pool(data=X_train, label=y_train, weight=weights_train, cat_features=['eSportsLeague_1', 'eSportsLeague_2', 'team_1', 'team_2'])\n",
    "X_val = X_val.drop('tournament_name', axis=1)\n",
    "X_val = X_val[model_features]\n",
    "val_data = Pool(data=X_val, label=y_val, cat_features=['eSportsLeague_1', 'eSportsLeague_2', 'team_1', 'team_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595541bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prior on feature importances \n",
    "important_features = ['outcome_domestic', 'outcome_international', 'eSportsLeague_1', 'eSportsLeague_2', \n",
    "                      'team_share_of_totalGold_at_game_end', 'team_share_of_towerKills_at_game_end', 'team_share_of_VISION_SCORE_at_game_end']\n",
    "important_features_weights = {\n",
    "    'outcome_domestic': 10, \n",
    "    'outcome_international': 0, \n",
    "    'eSportsLeague_1': 3, \n",
    "    'eSportsLeague_2': 3, \n",
    "    'team_share_of_totalGold_at_game_end': 8, \n",
    "    'team_share_of_towerKills_at_game_end': 8, \n",
    "    'team_share_of_VISION_SCORE_at_game_end': 8\n",
    "}\n",
    "important_features_ix = [X_train.columns.tolist().index(x) for x in important_features]\n",
    "\n",
    "# Assign a feature weight of 2 for all of the important features and 1 for everything else\n",
    "feature_weights = [1 for x in range(len(X_train.columns))]\n",
    "for feature, weight in important_features_weights.items():\n",
    "    feature_ix = X_train.columns.tolist().index(feature)\n",
    "    feature_weights[feature_ix] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0eb6e07a4305e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:02:28.349855100Z",
     "start_time": "2023-10-01T05:56:44.590060800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning - tune over common boosting parameters \n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_categorical(\"iterations\", [25, 50, 100, 200]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 5, 10),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 30),\n",
    "        \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\", 1, 30),\n",
    "        \"random_strength\": trial.suggest_categorical(\"random_strength\", [0.5, 1, 1.5, 2, 3, 4])\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params, cat_features=['eSportsLeague_1', 'eSportsLeague_2', 'team_1', 'team_2'], feature_weights=feature_weights, task_type=\"GPU\", devices='0:1', silent=True)\n",
    "    model.fit(train_data)\n",
    "    predictions = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297ac8cf8cae108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:02:45.648809400Z",
     "start_time": "2023-10-01T06:02:28.346858300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the best parameters and fit a new model on the data based on it\n",
    "print(study.best_params)\n",
    "model = CatBoostClassifier(**study.best_params, cat_features=['eSportsLeague_1', 'eSportsLeague_2', 'team_1', 'team_2'], feature_weights=feature_weights, task_type=\"GPU\", devices='0:1', silent=True)\n",
    "\n",
    "# Train on the FULL data \n",
    "model.fit(X.drop('tournament_name', axis=1)[model_features], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3515976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_model('catboost_model.cbm', pool = Pool(X.drop('tournament_name', axis=1)[model_features], y, cat_features=['eSportsLeague_1', 'eSportsLeague_2', 'team_1', 'team_2']))\n",
    "model = CatBoostClassifier()\n",
    "model.load_model(\"catboost_model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33107888d82278e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:03:42.690480900Z",
     "start_time": "2023-10-01T06:03:42.606479100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the feature importance of the model\n",
    "pd.DataFrame({x: y for x, y in zip(X_train.columns, model.get_feature_importance())}, index = [0]).T.sort_values(by=0, ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ecca3999a969f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:24:34.014613300Z",
     "start_time": "2023-10-01T06:24:33.925764400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the model on a specific game \n",
    "tournament_data = model_data[model_data['tournament_name']=='lcs_spring_2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for helping to find the closest key in a dictionary \n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def find_closest_key(string, dictionary):\n",
    "    closest_key = None\n",
    "    closest_distance = 0\n",
    "    \n",
    "    for key in dictionary.keys():\n",
    "        distance = SequenceMatcher(None, string, key).ratio()\n",
    "        if distance > closest_distance:\n",
    "            closest_key = key\n",
    "            closest_distance = distance\n",
    "    print(closest_key)\n",
    "    return dictionary[closest_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18915911",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_dict_rev = {v:k for (k,v) in data_aggregator.teams_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds_teams = ['Gen.G', 'T1', 'KT Rolster', 'Dplus', 'Cloud9', 'NRG', 'Team Liquid', 'WeiboGaming FAW Audi', 'Beijing JDG Intel', 'bilibili', 'suzhou LNG',\n",
    "    'g2 esports', 'fnatic', 'MAD lions', 'golden guardians', 'team BDS', 'LOUD', 'GAM esports', 'TEAM WHALES', 'psg talon', 'ctbc flying oyster', 'detonation focusme', \n",
    "    'Movistar R7']\n",
    "\n",
    "worlds_team_ids = [int(find_closest_key(x, teams_dict_rev)) for x in worlds_teams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a74681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataGenerator:\n",
    "    \"\"\"\n",
    "    Class to generate inference data for Tournament, Team, and Global rankings \n",
    "    \"\"\"\n",
    "    def __init__(self, game_data, model_features) -> None:\n",
    "        self.model_features = model_features\n",
    "        self.numeric_model_features = np.intersect1d(game_data._get_numeric_data().columns, model_features)\n",
    "        self.special_features = ['outcome_domestic', 'outcome_international']\n",
    "        self.game_data = game_data\n",
    "        # It turns out that adding boost factors is important for maintaining the general ordering of regions (based on previous international tournaments)\n",
    "        self.additive_boost_factors = {\n",
    "            # Major regions\n",
    "            'LCK': 0.3,\n",
    "            'LPL': 0.3,\n",
    "            'LEC': 0.20,\n",
    "            'LCS': 0.15,\n",
    "            # Minor regions below\n",
    "            # 'PCS': 0.05,\n",
    "            # 'LLA': 0.04,\n",
    "            # 'CBLOL': 0.03,\n",
    "            # 'VCS': 0.02,\n",
    "            # 'LJL': 0.01,\n",
    "        }\n",
    "        # Mark important features to boost in international competitions\n",
    "        self.columns_to_boost = ['outcome_domestic', 'team_share_of_totalGold_at_game_end', 'team_share_of_towerKills_at_game_end', 'team_share_of_VISION_SCORE_at_game_end']\n",
    "\n",
    "    def get_inference_data_by_team_id(self, team_ids):\n",
    "        game_data = self.get_game_data_by_team_id(team_ids)\n",
    "        for column in self.columns_to_boost:\n",
    "            game_data[column] *= game_data['eSportLeague'].map(self.additive_boost_factors).fillna(0)\n",
    "        tournament_rows = self.get_tournament_rows_by_team_id(team_ids)\n",
    "        inference_data = self.get_inference_data(tournament_rows, game_data)\n",
    "        return inference_data \n",
    "\n",
    "    def get_game_data_by_team_id(self, team_ids):\n",
    "        \"\"\"\n",
    "        Gets the last game played for each team_id \n",
    "        \"\"\"\n",
    "        game_data = self.game_data[self.game_data['team_id'].isin(team_ids)]\n",
    "        game_data = game_data.sort_values(by=['team_id', 'start_time'])\n",
    "        game_data = game_data.drop_duplicates(subset=['team_id'], keep='last')\n",
    "        return game_data\n",
    "\n",
    "    def get_tournament_rows_by_team_id(self, team_ids):\n",
    "        \"\"\"\n",
    "        Creates an imaginary round-robin tournament\n",
    "        \"\"\"\n",
    "        tournament_rows = []\n",
    "        for team_1 in team_ids:\n",
    "            for team_2 in team_ids:\n",
    "                tournament_rows.append([team_1, team_2])\n",
    "                    \n",
    "        # Format this as a table\n",
    "        tournament_rows = pd.DataFrame(tournament_rows, columns=['team_id_1', 'team_id_2'])\n",
    "        return tournament_rows\n",
    "\n",
    "    def get_inference_data(self, tournament_rows, game_data):\n",
    "        tournament_rows_featurized_1 = tournament_rows.merge(game_data, how='left', left_on=['team_id_1'], right_on=['team_id'])\n",
    "        tournament_rows_featurized_2 = tournament_rows.merge(game_data, how='left', left_on=['team_id_2'], right_on=['team_id'])\n",
    "\n",
    "        # Compute the difference between the two teams (with additional checks to ensure that no shuffling occurred during the join)\n",
    "        check_team1_id = np.all(tournament_rows_featurized_1['team_id_1'] == tournament_rows_featurized_2['team_id_1'])\n",
    "        check_team2_id = np.all(tournament_rows_featurized_1['team_id_2'] == tournament_rows_featurized_2['team_id_2'])\n",
    "        check_team1_id_base = np.all(tournament_rows['team_id_1'] == tournament_rows_featurized_1['team_id_1'])\n",
    "        check_team2_id_base = np.all(tournament_rows['team_id_2'] == tournament_rows_featurized_1['team_id_2'])\n",
    "\n",
    "        if check_team1_id and check_team2_id and check_team1_id_base and check_team2_id_base:\n",
    "            # Calculate the difference between the two teams for each feature\n",
    "            difference_data = tournament_rows_featurized_1[self.numeric_model_features].subtract(tournament_rows_featurized_2[self.numeric_model_features])\n",
    "            for feature in self.special_features:\n",
    "                # Calculate the difference between columns A and B\n",
    "                diff = tournament_rows_featurized_1[feature].fillna(0).sub(tournament_rows_featurized_2[feature].fillna(0)) \n",
    "                # If both columns are nan then mark the difference as nan\n",
    "                diff[(tournament_rows_featurized_1[feature].isna()) & (tournament_rows_featurized_2[feature].isna())] = np.nan\n",
    "                difference_data[feature] = diff\n",
    "        else:\n",
    "            raise Exception('esportsGameId is not the same for the two teams')\n",
    "                \n",
    "        # Add the difference data to the tournament_rows dataframe as well as the league data for each team\n",
    "        training_data = deepcopy(tournament_rows)\n",
    "        training_data = pd.concat([training_data.reset_index(), difference_data], axis=1)\n",
    "        training_data['eSportsLeague_1'] = tournament_rows_featurized_1['eSportLeague']\n",
    "        training_data['eSportsLeague_2'] = tournament_rows_featurized_2['eSportLeague']\n",
    "        training_data['domestic_game_ind'] = training_data['eSportsLeague_1'] == training_data['eSportsLeague_2']\n",
    "        training_data['eliteLeague_1'] = tournament_rows_featurized_1['eliteLeague']\n",
    "        training_data['eliteLeague_2'] = tournament_rows_featurized_2['eliteLeague']\n",
    "        training_data['majorLeague_1'] = tournament_rows_featurized_1['majorLeague']\n",
    "        training_data['majorLeague_2'] = tournament_rows_featurized_2['majorLeague']\n",
    "        training_data['team_1'] = tournament_rows_featurized_1['team_name']\n",
    "        training_data['team_2'] = tournament_rows_featurized_2['team_name']\n",
    "        training_data['start_time'] = tournament_rows_featurized_1['start_time']\n",
    "        training_data['year'] = tournament_rows_featurized_1['year']\n",
    "\n",
    "        # Drop the columns that were used for joining (have '_to_drop' suffix). \n",
    "        training_data.drop([x for x in training_data.columns if '_to_drop' in x] + ['index'], axis=1, inplace=True)\n",
    "        training_data = training_data.drop(['team_id_1', 'team_id_2', 'start_time'], axis=1)\n",
    "\n",
    "        return training_data[self.model_features]\n",
    "    \n",
    "    \n",
    "class InferenceModel:\n",
    "    def __init__(model) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is code to generate the inference data \n",
    "\n",
    "numeric_model_features = np.intersect1d(game_data._get_numeric_data().columns, model_features)\n",
    "\n",
    "# Check for features that are created during processing steps that aren't numeric\n",
    "set(model_features) - set(numeric_model_features)\n",
    "\n",
    "# excluded_features are features that are generated during processing, so it's not necessary to save them\n",
    "excluded_features = set(['eSportsLeague_1', 'eSportsLeague_2', 'eliteLeague_1', 'eliteLeague_2', 'majorLeague_1', 'majorLeague_2', 'team_1', 'team_2', 'domestic_game_ind'])\n",
    "model_features_save = list(set(model_features) - excluded_features)\n",
    "\n",
    "# Include features that are excluded from the data processing (or are processed in a separate manner than the other features)\n",
    "game_data_inf = game_data[['platformGameId', 'esportsGameId', 'team_id', 'start_time'] + ['team_name', 'eSportLeague', 'eliteLeague', 'majorLeague'] + model_features_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6450079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the formatted data to run inference on later \n",
    "# game_data_inf.to_csv('game_data.csv', index=False)\n",
    "\n",
    "# Read in data and artifacts required for inference\n",
    "game_data_inf = pd.read_csv('game_data.csv')\n",
    "\n",
    "with open(\"model_features.txt\", \"rb\") as fp:   # Unpickling\n",
    "    model_features = pickle.load(fp)\n",
    "\n",
    "game_data_inf = pd.read_csv('game_data.csv')\n",
    "\n",
    "model = CatBoostClassifier()\n",
    "model.load_model(\"catboost_model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have the model we can make pairwise predictions and use those \n",
    "\n",
    "team_ids = worlds_team_ids\n",
    "\n",
    "inference_data_generator = InferenceDataGenerator(game_data_inf, model_features)\n",
    "X_inference = inference_data_generator.get_inference_data_by_team_id(team_ids)\n",
    "\n",
    "## Probabilistic prediction\n",
    "# Prediction creates an N x N matrix where N is the len(unique_team_ids)\n",
    "tournament_preds = model.predict_proba(X_inference)[:,1]\n",
    "# Format the predictions into an N x N matrix (fill by row) \n",
    "tournament_preds = tournament_preds.reshape(len(team_ids), len(team_ids))\n",
    "# Multiply the values less than 0.5 by -1 to get the correct sign\n",
    "tournament_preds[tournament_preds < 0.5] = tournament_preds[tournament_preds < 0.5]*-1\n",
    "# Mark the diagonal as 0's\n",
    "np.fill_diagonal(tournament_preds, 0.0)\n",
    "\n",
    "## Deterministic prediction\n",
    "# Prediction creates an N x N matrix where N is the len(unique_team_ids)\n",
    "# tournament_preds = model.predict(X_inference)\n",
    "# # Format the predictions into an N x N matrix (fill by row) \n",
    "# tournament_preds = tournament_preds.reshape(len(team_ids), len(team_ids))\n",
    "# # Convert the 0's into -1 (means they lost)\n",
    "# tournament_preds[tournament_preds==0] = -1\n",
    "# # Mark the diagonal as 0's\n",
    "# np.fill_diagonal(tournament_preds, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b4ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.utils.serialrank import SerialRank\n",
    "\n",
    "# We can use serial rank if we want to apply a spectral ranking algorithm\n",
    "# The idea for spectral ranking is that teamms that win/lose against similar teams should be ranked similarly\n",
    "# Empirically, this tends to not work as well as the probabilistic predictions\n",
    "serial_rank = SerialRank(tournament_preds)\n",
    "serial_rank.fit()\n",
    "team_scores = serial_rank.r.squeeze()\n",
    "\n",
    "# Rank the teams based on the scores\n",
    "team_names = [data_aggregator.teams_dict[str(x)] for x in team_ids]\n",
    "team_ranks = pd.DataFrame({'team_name': team_names, 'score': team_scores}).sort_values(by='score', ascending=True)\n",
    "team_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff94f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another option is to rank with the pairwise probabilistic predictions. This ignores who wins against who, and simply places the winningest teams at the top\n",
    "team_scores = np.sum(tournament_preds, axis=1)\n",
    "team_names = [data_aggregator.teams_dict[str(x)] for x in team_ids]\n",
    "team_ranks = pd.DataFrame({'team_name': team_names, 'score': team_scores}).sort_values(by='score', ascending=False)\n",
    "team_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c251e729c7885f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T18:30:42.739184600Z",
     "start_time": "2023-10-01T18:30:42.553907Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Below is the logic for computing shapley values\n",
    "\n",
    "# Take the (column-wise) mean of the shap_values for each n-sized block of rows (representing the games that a specific team plays)\n",
    "# Skip the first row of each block since tat's the difference between the first team and itself\n",
    "N_teams = len(team_ids)\n",
    "for i in range(0, len(shap_values), N_teams):\n",
    "    if i == 0:\n",
    "        team_shap_values = shap_values[i+1:i+N_teams].values.mean(axis=0)\n",
    "    else:\n",
    "        team_shap_values = np.vstack((team_shap_values, shap_values[i+1:i+N_teams].values.mean(axis=0)))\n",
    "\n",
    "# Label the shap values with the team names and feature names\n",
    "# team_shap_values = pd.DataFrame(team_shap_values, columns=model_features, index=team_names)\n",
    "team_shap_values = pd.DataFrame(team_shap_values, columns=X_inference.columns, index=team_names)\n",
    "\n",
    "# shap_features_to_exclude = ['team_1', 'team_2', 'outcome_domestic', 'outcome_international', 'domestic_game_ind', 'eliteLeague_1', 'eliteLeague_2', \n",
    "#     'majorLeague_1', 'majorLeague_2', 'eSportsLeague_1', 'eSportsLeague_2', 'year', 'team_share_of_totalGold_at_20', 'team_share_of_totalGold_at_game_end',\n",
    "#     'team_share_of_towerKills_at_20', 'team_share_of_towerKills_at_game_end', 'team_share_of_VISION_SCORE_at_game_end', 'support_NEUTRAL_MINIONS_KILLED_at_30']\n",
    "# shap_features_to_exclude = ['team_1', 'team_2']\n",
    "shap_features_to_exclude = []\n",
    "# Drop the features that are in the shap_features_to_exclude list (not interpretable)\n",
    "team_shap_values = team_shap_values.drop(shap_features_to_exclude, axis=1)\n",
    "\n",
    "# For each team, get the top 5 most positive features and top 5 most negative features and put them into the columns ['top_1_pos', 'top_2_pos', ..., 'top_1_neg', 'top_2_neg', ..., 'top_5_neg']\n",
    "# Define a custom function to get the top 5 most positive and negative features for a team\n",
    "def get_top_features(row):\n",
    "    top_pos = row.sort_values(ascending=False)[:5].index.tolist()\n",
    "    top_neg = row.sort_values(ascending=True)[:5].index.tolist()\n",
    "    return pd.Series(top_pos + top_neg, index=[f'top_{i}_pos' for i in range(1, 6)] + [f'top_{i}_neg' for i in range(1, 6)])\n",
    "\n",
    "# Apply the custom function to each row of the team_shap_values dataframe\n",
    "team_top_features = team_shap_values.apply(get_top_features, axis=1)\n",
    "\n",
    "team_top_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
