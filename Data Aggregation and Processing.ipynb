{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f1f6f4",
   "metadata": {},
   "source": [
    "# Tournaments Processing\n",
    "\n",
    "This notebook iterates through all tournaments in a given year, downloads each game of the tournament, processes them by iterating through each frame, and condenses them into a single row of data. We then later save this data for modeling and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T01:24:39.586241100Z",
     "start_time": "2023-09-30T01:24:39.492267600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from data_processing.GameFeaturesGenerator import GameFeaturesGenerator\n",
    "from data_processing.TournamentDataProcessor import TournamentDataProcessor\n",
    "from data_processing.LeaguesDataProcessor import LeaguesDataProcessor\n",
    "from data_processing.utils.download_functions import *\n",
    "os.chdir('esports-data')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8656c62cc1eb9cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T01:24:39.730069700Z",
     "start_time": "2023-09-30T01:24:39.668204700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in teams data\n",
    "with open(\"teams.json\", \"r\") as json_file:\n",
    "   teams_data = json.load(json_file)\n",
    "\n",
    "team_df = []\n",
    "for team in teams_data:\n",
    "    team_df.append({'team_id': team['team_id'], 'team_name': team['name']})\n",
    "    \n",
    "team_df = pd.DataFrame(team_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4a569c20e4b92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T01:24:41.327998900Z",
     "start_time": "2023-09-30T01:24:39.846817800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in tournament data\n",
    "with open(\"tournaments.json\", \"r\") as json_file:\n",
    "   tournament_data_all = json.load(json_file)\n",
    "\n",
    "# Read in mappings data\n",
    "with open(\"mapping_data.json\", \"r\") as json_file:\n",
    "   mappings_data = json.load(json_file)\n",
    "   \n",
    "mappings = {\n",
    "   esports_game[\"esportsGameId\"]: esports_game for esports_game in mappings_data\n",
    "}\n",
    "\n",
    "# Set up LeaguesDataProcessor\n",
    "leagues_data_processor = LeaguesDataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bed265b7f7c676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T01:24:56.590819500Z",
     "start_time": "2023-09-30T01:24:56.574331200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tournaments_year = [x['slug'] for x in tournament_data_all if '2023' in x['slug']]\n",
    "\n",
    "tournaments = [x for x in tournament_data_all if x['slug'] in tournaments_year]\n",
    "tournaments_names = [x['slug'] for x in tournaments]\n",
    "print(tournaments_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9ee81cadf5142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T01:24:49.455785Z",
     "start_time": "2023-09-30T01:24:49.436835500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tournaments = [x for x in tournament_data_all if x['slug'] in ['pcs_summer_playoffs_2023']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc1fcacb049195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T04:58:53.629286700Z",
     "start_time": "2023-09-30T01:24:58.924889100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterate through each tournament and process the data, we will get two dataframes \n",
    "\n",
    "tournament_rows = [match_id, esportsGameId, league, team_id_1, team_id_2, outcome_1, outcome_2]\n",
    "game_rows = [platformGameId, esportsGameId, team_id, start_time, outcome, ...features..., ...league_indicators...]]\n",
    "\n",
    "Save these dataframes to csv files in the data folder with the corresponding tournament name \n",
    "\"\"\"\n",
    "\n",
    "for tournament_data in tournaments:\n",
    "    tournament_name = tournament_data['slug']\n",
    "    print(\"Processing: \" + tournament_name)\n",
    "    # Set up TournamentDataProcessor\n",
    "    try:\n",
    "        tournament_data_processor = TournamentDataProcessor(tournament_data, leagues_data_processor.leagues_df)\n",
    "    except IndexError as e:\n",
    "        print(f\"Error processing tournament {tournament_name}. Tournament could not be found in leagues data\")\n",
    "        continue\n",
    "    # tournament_data_processor.get_tournament_stages()\n",
    "    training_data, _ = tournament_data_processor.get_tournament_data(training_stages=[], testing_stages=[])  # Consider all stages to be training \n",
    "    print(\"Games in tournament: \" + str(len(training_data)))\n",
    "    \n",
    "    # Now download each game, process them, and add them into game_rows \n",
    "    directory = \"games\"\n",
    "    if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "    \n",
    "    # Load each game and process them\n",
    "    game_rows = []\n",
    "    for i in tqdm(range(len(training_data))):\n",
    "        try:\n",
    "            game_id = training_data.iloc[i]['esportsGameId']\n",
    "            game_mapping_data = mappings[game_id]\n",
    "            platform_game_id = game_mapping_data['platformGameId']\n",
    "            download_gzip_and_write_to_json(f\"{directory}/{platform_game_id}\")\n",
    "            with open(f\"games/{platform_game_id}.json\", \"r\") as json_file:\n",
    "                game_data = json.load(json_file)\n",
    "        except KeyError:\n",
    "            print(f\"Match {game_id} was not found\")\n",
    "            continue\n",
    "        try:\n",
    "            game_features = GameFeaturesGenerator(game_data, game_mapping_data).process_game()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing game {game_id}\")\n",
    "            print(e)\n",
    "            continue\n",
    "        game_features['league'] = training_data.iloc[i]['league']\n",
    "        game_rows.append(game_features)\n",
    "    \n",
    "    game_rows = pd.concat(game_rows)\n",
    "    game_rows_leagues = leagues_data_processor.transform_league_col(game_rows['league'])\n",
    "    game_rows = pd.concat([game_rows.drop(['league'],axis=1).reset_index(), game_rows_leagues], axis=1)\n",
    "    \n",
    "    # Save to csv in the data folder\n",
    "    game_data_directory = \"2023_raw_game_data\"\n",
    "    if not os.path.exists(game_data_directory):\n",
    "      os.makedirs(game_data_directory)\n",
    "    training_data.to_csv(f'{game_data_directory}/{tournament_name}_tournament_rows.csv', index=False)\n",
    "    game_rows.to_csv(f'{game_data_directory}/{tournament_name}_game_rows.csv', index=False)\n",
    "    \n",
    "    # Delete the temp directory\n",
    "    shutil.rmtree(directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
